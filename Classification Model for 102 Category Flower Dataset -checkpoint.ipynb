{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2229504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ccb8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=r\"C:\\Users\\user\\Downloads\\Compressed\\102flowers\\102flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d789d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2586 images belonging to 4 classes.\n",
      "Found 285 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE=224\n",
    "BATCH_SIZE=64\n",
    "\n",
    "#pre=processing\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1\n",
    "    )\n",
    "\n",
    "test_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "     rescale=1./255,\n",
    "     validation_split=0.1\n",
    ")\n",
    "\n",
    "train_datagen=train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_datagen=test_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a84f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,padding='same',strides=2,kernel_size=3,activation='relu',input_shape=(224,224,3)))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5442af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "085cdbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "41/41 [==============================] - 124s 3s/step - loss: 1.1912 - accuracy: 0.4408 - val_loss: 1.0750 - val_accuracy: 0.4596\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 89s 2s/step - loss: 0.9704 - accuracy: 0.5599 - val_loss: 1.0217 - val_accuracy: 0.5263\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 91s 2s/step - loss: 0.8824 - accuracy: 0.6141 - val_loss: 0.9060 - val_accuracy: 0.6386\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 89s 2s/step - loss: 0.8479 - accuracy: 0.6427 - val_loss: 0.9361 - val_accuracy: 0.6175\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 92s 2s/step - loss: 0.7950 - accuracy: 0.6779 - val_loss: 0.8347 - val_accuracy: 0.6947\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 91s 2s/step - loss: 0.7313 - accuracy: 0.7189 - val_loss: 0.7714 - val_accuracy: 0.7368\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 91s 2s/step - loss: 0.7194 - accuracy: 0.7131 - val_loss: 0.7680 - val_accuracy: 0.7193\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.6987 - accuracy: 0.7312 - val_loss: 0.7771 - val_accuracy: 0.7123\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.6920 - accuracy: 0.7386 - val_loss: 0.7852 - val_accuracy: 0.7158\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.6572 - accuracy: 0.7428 - val_loss: 0.8589 - val_accuracy: 0.7123\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.6321 - accuracy: 0.7560 - val_loss: 0.7423 - val_accuracy: 0.7263\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 95s 2s/step - loss: 0.6380 - accuracy: 0.7544 - val_loss: 0.7071 - val_accuracy: 0.7368\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 94s 2s/step - loss: 0.6014 - accuracy: 0.7660 - val_loss: 0.7752 - val_accuracy: 0.6982\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 92s 2s/step - loss: 0.5945 - accuracy: 0.7761 - val_loss: 0.6893 - val_accuracy: 0.7579\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 93s 2s/step - loss: 0.5896 - accuracy: 0.7668 - val_loss: 0.6821 - val_accuracy: 0.7544\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 92s 2s/step - loss: 0.5732 - accuracy: 0.7850 - val_loss: 0.7922 - val_accuracy: 0.7123\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.5681 - accuracy: 0.7807 - val_loss: 0.6899 - val_accuracy: 0.7649\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.5521 - accuracy: 0.7831 - val_loss: 0.7122 - val_accuracy: 0.7439\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 87s 2s/step - loss: 0.5539 - accuracy: 0.7854 - val_loss: 0.6712 - val_accuracy: 0.7579\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 87s 2s/step - loss: 0.5691 - accuracy: 0.7761 - val_loss: 0.7971 - val_accuracy: 0.7368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cc1c973210>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train_datagen,epochs=20,validation_data=test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f156acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a5347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
